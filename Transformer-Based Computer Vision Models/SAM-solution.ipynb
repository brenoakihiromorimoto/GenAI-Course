{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "004cbcfd",
   "metadata": {},
   "source": [
    "# Image Segmentation with SAM (Segment Anything Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2483243",
   "metadata": {},
   "source": [
    "In this exercise, we delve into the world of image segmentation using the advanced SAM (Segment Anything Model). We will explore how to employ this model for segmenting specific parts of an image, a crucial step in various computer vision tasks. By the end, we'll segment an image of a butterfly by providing SAM with a bounding box. We'll see it segment the butterfly with extreme precision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd73d8d",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5caacca6",
   "metadata": {},
   "source": [
    "First, let's import the necessary libraries. We use OpenCV for image processing, NumPy for numerical operations, and Matplotlib for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e3f4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from segment_anything import sam_model_registry, SamPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc25df2",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0f2388",
   "metadata": {},
   "source": [
    "To effectively visualize our segmentation results, we define some helper functions. These functions will assist us in overlaying segmentation masks and drawing bounding boxes on our images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c78d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_mask(mask, ax):\n",
    "    color = np.array([30/255, 144/255, 255/255, 0.6]) # An opaque blue color we'll use to indicate the mask\n",
    "    \n",
    "    # TODO: Implement the function to overlay a color mask on the image. \n",
    "    # Hint: Using the color array, reshape the mask, and multiply with the color for overlay.\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "\n",
    "\n",
    "def show_box(box, ax):\n",
    "    # TODO: Complete this function to draw a bounding box on the image.\n",
    "    # Hint: Use plt.Rectangle to draw the box.\n",
    "    \n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af5745",
   "metadata": {},
   "source": [
    "## Loading and Preparing the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f7b87b9",
   "metadata": {},
   "source": [
    "We will now load a pre-trained SAM model. SAM models are potent for various segmentation tasks and come with pre-trained weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc087cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the SAM model with pre-trained weights\n",
    "sam_checkpoint = \"/home/student/sam-hq/pretrained_checkpoint/sam_hq_vit_l.pth\"\n",
    "model_type = \"vit_l\"\n",
    "device = \"cpu\"\n",
    "\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "predictor = SamPredictor(sam)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "637f669e",
   "metadata": {},
   "source": [
    "## Image Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c25972d1",
   "metadata": {},
   "source": [
    "Next, we load an image for our segmentation task. We convert the image to the RGB color space, as the SAM model expects input in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5defe545",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess an image for segmentation\n",
    "image = cv2.imread('/home/student/sam-hq/demo/input_imgs/example1.png')\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6210cfb7",
   "metadata": {},
   "source": [
    "## Conducting and Visualizing Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b5919f",
   "metadata": {},
   "source": [
    "Let's perform the actual segmentation on our image. We'll define the input parameters for our segmentation task and apply the SAM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcf8c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters for segmentation\n",
    "input_box = np.array([[306, 132, 925, 893]]) # Do not change\n",
    "\n",
    "# Segmentation using SAM\n",
    "predictor.set_image(image)\n",
    "\n",
    "# TODO: Use the predictor to perform segmentation. Pay attention to the parameters and how they might affect the segmentation output.\n",
    "# Hint: You need to call predictor.predict() \n",
    "# Hint: Choose from below arguments:\n",
    "\"\"\"\n",
    "      point_coords (np.ndarray or None): A Nx2 array of point prompts to the\n",
    "        model. Each point is in (X,Y) in pixels.\n",
    "      point_labels (np.ndarray or None): A length N array of labels for the\n",
    "        point prompts. 1 indicates a foreground point and 0 indicates a\n",
    "        background point.\n",
    "      box (np.ndarray or None): A length 4 array given a box prompt to the\n",
    "        model, in XYXY format.\n",
    "      mask_input (np.ndarray): A low resolution mask input to the model, typically\n",
    "        coming from a previous prediction iteration. Has form 1xHxW, where\n",
    "        for SAM, H=W=256.\n",
    "\"\"\"\n",
    "# Hint: Use the argument \"hq_token_only = True\" for higher accuracy\n",
    "\n",
    "masks, scores, logits = predictor.predict(\n",
    "    box = input_box,\n",
    "    hq_token_only= True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bf267f",
   "metadata": {},
   "source": [
    "Next, let's write the segmentation visualization logic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee66116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_res(masks, scores, input_box, image):\n",
    "    # TODO: Iterate over the masks and scores, use the visualization functions to display the results.\n",
    "    # Hint: First display the image, then display mask and box on top\n",
    "    # Hint: Use plt.imshow(image)\n",
    "    # Hint: Use show_box and show_mask\n",
    "    \n",
    "    # TODO: Print the final score\n",
    "\n",
    "    for i, (mask, score) in enumerate(zip(masks, scores)):\n",
    "        plt.figure(figsize=(10,10))\n",
    "        plt.imshow(image)\n",
    "        \n",
    "        box = input_box[i]\n",
    "        \n",
    "        show_mask(mask, plt.gca())\n",
    "        show_box(box, plt.gca())\n",
    "        \n",
    "        print(f\"Score: {score:.3f}\")\n",
    "        \n",
    "        plt.axis('off')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc22c2df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the segmentation results\n",
    "show_res(masks, scores, input_box, image)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
